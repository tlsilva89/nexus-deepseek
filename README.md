# 🎆 Nexus DeepSeek 🎆

[![License: MIT](https://img.shields.io/badge/License-MIT-neonblue.svg)](https://opensource.org/licenses/MIT)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/seu-usuario/nexus-deepseek)
[![Ollama Version](https://img.shields.io/badge/Ollama-≥0.1.23-purple)](https://ollama.ai/)

Uma plataforma de chat para LLMs locais com privacidade total e controle completo sobre seus dados.

O **Nexus DeepSeek** é uma aplicação moderna, leve e 100% local para interação com **modelos de linguagem baseados em código**, usando o `deepseek-coder:8b` via [`ollama`](https://ollama.com). O foco é total em **privacidade**, **segurança** e **autonomia** — sem depender de nuvem, sem enviar dados para fora da sua máquina.

> 🔧 Basta rodar `ollama run deepseek-coder:8b` localmente e conectar!

## 🔐 Por que local?

- ✅ **Nenhum dado sensível sai da sua máquina**
- ✅ **Ideal para ambientes corporativos, educacionais e devs autônomos**
- ✅ **Zero custo com APIs externas e sem limite de uso**

## 💡 Objetivo

Oferecer uma **interface intuitiva, acessível e funcional** para interagir com o modelo `deepseek-coder:8b`, facilitando o uso em tarefas de desenvolvimento com foco em segurança e performance local.

## 🛠️ Pré-requisitos

- Ollama instalado e configurado
- Hardware recomendado:
  - CPU: 4+ núcleos (Intel/AMD)
  - RAM: 16GB+
  - GPU: Opcional (suporte a CUDA para aceleração)

## 🚀 Tecnologias

- ⚛️ ReactJS
- ⚡ Vite
- 🎨 Tailwind CSS
- 🔒 TypeScript
